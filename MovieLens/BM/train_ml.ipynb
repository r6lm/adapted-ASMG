{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from engine import *\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to df\n",
    "start_time = time.time()\n",
    "\n",
    "data_df = pd.read_csv('../../datasets/ml_5yr_2014_2018_30seq.csv')\n",
    "meta_df = pd.read_csv('../../datasets/ml_5yr_2014_2018_30seq_item_meta.csv')\n",
    "\n",
    "data_df['itemSeq'] = data_df['itemSeq'].fillna('')  # empty seq are NaN\n",
    "data_df['itemSeq'] = data_df['itemSeq'].apply(lambda x: [int(item) for item in x.split('#') if item != ''])\n",
    "meta_df['cateId'] = meta_df['cateId'].apply(lambda x: [int(cate) for cate in x.split('#') if cate != ''])\n",
    "meta_df = meta_df.sort_values(['itemId'], ascending=True).reset_index(drop=True)\n",
    "cate_ls = meta_df['cateId'].tolist()\n",
    "\n",
    "print('Done loading data! time elapsed: {}'.format(time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))))\n",
    "\n",
    "num_users = data_df['userId'].max() + 1\n",
    "num_items = data_df['itemId'].max() + 1\n",
    "num_cates = max([max(i) for i in cate_ls]) + 1\n",
    "cates, cate_lens = process_cate(cate_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_config = {'method': 'BM',\n",
    "#                 'dir_name': 'BM_train15-24_test25_10epoch',  # edit train test period range, number of epochs\n",
    "                'dir_name': None, # varies across time\n",
    "                'start_date': 20140101,  # overall train start date\n",
    "                'end_date': 20181231,  # overall train end date\n",
    "                'num_periods': 31,  # number of periods divided into\n",
    "#                 'train_start_period': 15,\n",
    "#                 'train_end_period': 24,\n",
    "                'train_periods': 10, \n",
    "                'train_start_period': None, # varies across time\n",
    "                'train_end_period': None, # varies across time\n",
    "                'test_start_period': 25,\n",
    "                'test_period': None, # varies across time\n",
    "                'train_set_size': None,\n",
    "                'test_set_size': None,\n",
    "\n",
    "                'base_optimizer': 'adam',  # base model optimizer: adam, rmsprop, sgd\n",
    "                'base_lr': None,  # base model learning rate\n",
    "                'base_bs': 1024,  # base model batch size\n",
    "                'base_num_epochs': 10,  # base model number of epochs\n",
    "                'shuffle': True,  # whether to shuffle the dataset for each epoch\n",
    "                }\n",
    "\n",
    "EmbMLP_hyperparams = {'num_users': num_users,\n",
    "                      'num_items': num_items,\n",
    "                      'num_cates': num_cates,\n",
    "                      'user_embed_dim': 8,\n",
    "                      'item_embed_dim': 8,\n",
    "                      'cate_embed_dim': 8,\n",
    "                      'layers': [40, 20, 10, 1]\n",
    "                      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort train data into periods based on num_periods: Each period has the same amount of observations\n",
    "data_df = data_df[(data_df['date'] >= train_config['start_date']) & (data_df['date'] <= train_config['end_date'])]\n",
    "data_df = data_df.sort_values(['timestamp']).reset_index(drop=True)\n",
    "records_per_period = int(len(data_df) / train_config['num_periods'])\n",
    "data_df['index'] = data_df.index\n",
    "data_df['period'] = data_df['index'].apply(lambda x: int(x / records_per_period) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['period'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df.period != train_config['num_periods'] + 1]  # delete last extra period at most one observation\n",
    "period_df = data_df.groupby('period')['date'].agg(['count', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"timestamp\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(['index', 'date', 'timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base():\n",
    "\n",
    "    # create an engine instance\n",
    "    engine = Engine(sess, base_model)\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch_id in range(1, train_config['base_num_epochs'] + 1):\n",
    "\n",
    "        print('Training Base Model Epoch {} Start!'.format(epoch_id))\n",
    "\n",
    "        base_loss_cur_avg = engine.base_train_an_epoch(epoch_id, train_set, train_config)\n",
    "        print('Epoch {} Done! time elapsed: {}, base_loss_cur_avg {:.4f}'.format(\n",
    "            epoch_id,\n",
    "            time.strftime('%H:%M:%S', time.gmtime(time.time() - train_start_time)),\n",
    "            base_loss_cur_avg))\n",
    "\n",
    "        test_auc, test_logloss = engine.test(test_set, train_config)\n",
    "        print('test_auc {:.4f}, test_logloss {:.4f}'.format(\n",
    "            test_auc,\n",
    "            test_logloss))\n",
    "        print('time elapsed {}'.format(time.strftime('%H:%M:%S', time.gmtime(time.time() - train_start_time))))\n",
    "\n",
    "        print('')\n",
    "\n",
    "        # save checkpoint\n",
    "        checkpoint_alias = 'Epoch{}_TestAUC{:.4f}_TestLOGLOSS{:.4f}.ckpt'.format(\n",
    "            epoch_id,\n",
    "            test_auc,\n",
    "            test_logloss)\n",
    "        checkpoint_path = os.path.join(checkpoints_dir, checkpoint_alias)\n",
    "        saver.save(sess, checkpoint_path)\n",
    "    \n",
    "    # update test statistics\n",
    "    test_aucs.append(test_auc)\n",
    "    test_loglosses.append(test_logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize test statistics containers\n",
    "test_aucs = []\n",
    "test_loglosses = []\n",
    "\n",
    "# range the test period \n",
    "for test_period in range(train_config[\"test_start_period\"] + 1, train_config[\"num_periods\"] + 1):\n",
    "    \n",
    "    # update train and test periods\n",
    "    train_config['train_start_period'] = test_period - train_config[\"train_periods\"]\n",
    "    train_config['train_end_period'] = test_period - 1\n",
    "    train_config['test_period'] = test_period\n",
    "#     print(\"\"\"train periods: {} - {}\\ttest period: {}\"\"\".format(\n",
    "#         train_start_period, train_end_period, test_period\n",
    "#     ))\n",
    "    train_config['dir_name'] = \"BM_train{}-{}_test{}_10epoch\".format(\n",
    "        *map(lambda k: train_config[k], [\n",
    "            \"train_start_period\", \"train_end_period\", \"test_period\"])\n",
    "    )\n",
    "\n",
    "#     print(train_config['base_lr'])\n",
    "\n",
    "    \n",
    "\n",
    "    orig_dir_name = train_config['dir_name']\n",
    "\n",
    "    for base_lr in [1e-3]:\n",
    "\n",
    "        print('')\n",
    "        print('base_lr', base_lr)\n",
    "\n",
    "        train_config['base_lr'] = base_lr\n",
    "\n",
    "        train_config['dir_name'] = orig_dir_name + '_' + str(base_lr)\n",
    "        print('dir_name: ', train_config['dir_name'])\n",
    "\n",
    "        # create current and next set\n",
    "        train_set = data_df[(data_df['period'] >= train_config['train_start_period']) &\n",
    "                            (data_df['period'] <= train_config['train_end_period'])]\n",
    "        test_set = data_df[data_df['period'] == train_config['test_period']]\n",
    "        train_config['train_set_size'] = len(train_set)\n",
    "        train_config['test_set_size'] = len(test_set)\n",
    "        print('train set size', len(train_set), 'test set size', len(test_set))\n",
    "\n",
    "        # checkpoints directory\n",
    "        checkpoints_dir = os.path.join('ckpts', train_config['dir_name'])\n",
    "        if not os.path.exists(checkpoints_dir):\n",
    "            os.makedirs(checkpoints_dir)\n",
    "\n",
    "        # write train_config to text file\n",
    "        with open(os.path.join(checkpoints_dir, 'config.txt'), mode='w') as f:\n",
    "            f.write('train_config: ' + str(train_config) + '\\n')\n",
    "            f.write('\\n')\n",
    "            f.write('EmbMLP_hyperparams: ' + str(EmbMLP_hyperparams) + '\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # train and test\n",
    "        \n",
    "        # build base model computation graph\n",
    "        tf.reset_default_graph()\n",
    "        base_model = EmbMLP(cates, cate_lens, EmbMLP_hyperparams, train_config=train_config)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "            # create saver\n",
    "            saver = tf.train.Saver(max_to_keep=80)\n",
    "            \n",
    "            train_base()\n",
    "        \n",
    "        # report results\n",
    "        average_auc = sum(test_aucs) / len(test_aucs)\n",
    "        average_logloss = sum(test_loglosses) / len(test_loglosses)\n",
    "        print('test aucs', test_aucs)\n",
    "        print('average auc', average_auc)\n",
    "        print('')\n",
    "        print('test loglosses', test_loglosses)\n",
    "        print('average logloss', average_logloss)\n",
    "\n",
    "        # write metrics to text file\n",
    "        with open(os.path.join(checkpoints_dir, 'test_metrics.txt'), mode='w') as f:\n",
    "            f.write('test_aucs: ' + str(test_aucs) + '\\n')\n",
    "            f.write('average_auc: ' + str(average_auc) + '\\n')\n",
    "            f.write('test_loglosses: ' + str(test_loglosses) + '\\n')\n",
    "            f.write('average_logloss: ' + str(average_logloss) + '\\n')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = [0.7095338490599356] + test_aucs\n",
    "losses = [0.6612049837216922] + test_loglosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumave(l): return np.cumsum(np.array(l)) / np.arange(1, len(l) + 1)\n",
    "\n",
    "    \n",
    "[f for f in cumave(aucs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in cumave(losses)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ASMG)",
   "language": "python",
   "name": "asmg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
